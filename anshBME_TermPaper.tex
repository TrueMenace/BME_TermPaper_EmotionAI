\documentclass[12pt]{article}

\usepackage{titlepic}
\usepackage{graphicx}

\usepackage{adjustbox}
\graphicspath{{images_anshBME/}}

\usepackage{hyperref}
\hypersetup{colorlinks = true, citecolor = blue, linkcolor = blue, urlcolor = blue}

\title{Basic Biomedical Engineering\\Term Paper\\.\\Emotion Artificial Intelligence}

\titlepic{\includegraphics[scale=1]{logo.jpg}}

\author{Submitted by: \\Name:- Ansh Shrivastava\\Email:- anshshrivastava29@gmail.com\\Roll No :- 21111011\\First Semester, Biomedical Engineering\\.\\Under the supervision of\\Saurabh Gupta Sir}
%\date{January 2022}


\begin{document}
\maketitle
\clearpage
\tableofcontents
\clearpage

\section{Abstract}
AI powered machines can interpret Human emotions.
Emotion Artificial Intelligence goes by various names, affective computing is one of those, another one is human centric intelligence but actually behind all of those names is exactly the same research topic: emotion AI. Automatic sensing and analysis of human behaviour; particularly facial behaviour is something that we focus here.Emotional recognition technology detects human emotions from emotion and its external manifestation from the labeled database.The AI can identify diffrent emotion and infers meaning through the integration of Facial Expressions, Voice tone, Gestures and Speech Patterns. Machine learning and deep learning algorithms are emotion recognition using AI.
\section{Introduction}
Insurance fraud is now detected by a combination of claim analysis, computer programmes, and private detectives. The entire cost of non-healthcare-related insurance fraud, according to the FBI, is roughly 40 billion dollar each year. However, a maturing emerging technology known as emotion artificial intelligence (AI) may be able to detect insurance fraud based on caller audio analysis. Insurance fraud is now detected by a combination of claim analysis, computer programmes, and private detective.
\section{Emotion Artificial Intelligence}
Artificial intelligence that recognises and interprets human emotional signals is known as Emotion AI. Text (natural language processing and sentiment analysis), audio (voice emotion AI), video (facial movement analysis, gait analysis, and physiological data), and combinations of these sources are all possibilities.
It is also known as Affective Computing or Artificial Emotional Intelligence, and it is one of the emerging areas of Artificial Intelligence in which robots analyse nonverbal signs such as body language, facial expressions, gestures, and voice tone to determine a person's emotional state. Advertising, customer service, healthcare, and other fields have begun to benefit greatly from this technology.
\\
\begin{figure}[h]
\centering
\includegraphics[scale=0.3]{TP1.jpg}
\label{fig_1}
\end{figure}
\\
Emotions have a huge impact on how we behave. That may also – and in fact especially – be seen along the customer journey from a marketing standpoint. Customers are considerably more likely to be loyal to a brand if they have favourable emotional connotations with it than if the recalled associations are distant or even negative. As a result, if marketers want to improve the consumer experience, they'll need a system that is capable of more than just rational intelligence, Basically they need a system that is also able to:
\begin{itemize}
 \item learn from every interaction, \item understand both the cognitive and emotive pathway of human communication, \item sense intentions, and \item distinguish between literal and non-literal statements
\end{itemize}
In short marketers need emotion AI
\section{Industries that are already using Emotion AI}
\subsection{Call Centers}
Cogito's technology allows call centre agents to detect consumers' moods over the phone and alter how they conduct the discussion in real time. To identify vocal patterns, Cogito's voice-analytics software is built on years of human behaviour study.
\subsection{Mental Health}
CompanionMx, a companion mental health monitoring app, listens to someone speaking into their phone and analyses their speech and phone usage for symptoms of anxiety and mood shifts. The programme boosts users' self-awareness and can help them develop coping skills, such as stress-reduction techniques. Another emotion AI-driven tool for mental health is a wearable gadget developed by the MIT Media Lab that measures a person’s heartbeat to detect whether they are experiencing something like stress, discomfort, or annoyance. The monitor then emits a smell to assist the wearer in adjusting to the negative emotion they're experiencing. The BioEssence wearable detects stress or discomfort and emits a smell to assist the user in coping with the negative feeling.
\subsection{Automotive}
While there has been a lot of focus on safety in the environment outside of a car, there are a variety of distractions that might affect safety inside. Consider an automobile that could detect an argument between a driver and the passenger next to them based on rising blood pressure and modify the driver's speed accordingly. Or a sensor that alerted the steering wheel to gently guide the car into the centre of the lane when a sleep-deprived driver unintentionally veered off the road and into the kerb.Affectiva has its own automotive AI service that analyses a driver's state and the experiences of the occupants in order to improve road safety and the occupant experience.
\section{SCOPE of Emotion AI}
Emotion AI isn't just for talking. Sentiment analysis is a natural language processing technique that recognises and measures the emotional tenor of text samples, whether little or large. It has progressed to the point where it is now a widely used tool in a variety of industries, from marketing to banking, where it may be used to forecast stock movements. Video signals are also present. This covers not only face expression analysis, but also gait analysis and video analysis of specific physiological data. (Under the correct circumstances, a person's respiration and heart rate can be detected contactlessly using cameras.)
\subsection{Text Emotion AI: NLP and Sentiment Analysis}
Sentiment analysis is the technique of analysing text samples using natural language processing to identify whether the stated sentiments are good or negative, and to what extent. When firms utilise the approach to examine posted reactions to their products or services, this is a popular application.
\subsection{Audio and Voice Emotion AI}
Two businesses that are working on it are Behavioral Signals and Cogito. Both businesses create voice emotion AI for call centres, but they work in distinct ways. Cogito's technology focuses on giving real-time feedback to agents, whereas Behavioral Signals' technology focuses on identifying the optimal match between agents and the people they call. Furthermore, Behavioral Signals only analyses vocal data, not conversation content, whereas Cogito analyses both.
\subsection{Video and Multimodal Emotion AI}
If you analyse skin pixels with a camera and a simple signal-processing technique, you can usually extract a pulse signal and identify respiration for a stationary person. When you consider that it must work when people are moving, lighting may change, and everyone has varied skin pigmentation and facial hair, deep learning can assist to make it more resilient to all of these kinds of noise. The camera is sensitive enough to detect the first signal, but it is frequently overpowered by other variations that are unrelated to physiological changes. Deep learning is beneficial because it excels at these complex mappings.
\section{Discussion and Conclusion}
Although emotional artificial intelligence can be used for really great purposes and great good it can be badly misused but it is especially the case if we carelessly and blindly give our behavioral data to certain companies so this is exactly what's happening nowadays I mean you go to any website they ask you to clicking except these cookies right what are the cookies the cookies are actually the search patterns of what you do what did you search to which website you went how many times you visited that website what did you purchase how many times you purchase that so they have four behavioral pattern of your purchasing behavior then we go to this Facebook we open the profile we put our pictures with P to put our children's picture we put our friends then we tag everybody we put videos so they give everything they  have the faces they have the behavioral patterns they have how we smile which is a dynamic thing right they have can we walk what makes us happy where we go most often so then you go back to their part and then you realize how harmful that can be so the message for today really is be aware get informed you don't have to click on all of these cookies all the time you can actually scroll without accepting the cookies take care what kind of information you give away and keep your own data for your own. THANK YOU
\end{document}